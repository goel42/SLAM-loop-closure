{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import toml\n",
    "import time\n",
    "from ipywidgets import *\n",
    "import cv2\n",
    "import uuid\n",
    "from absl import logging\n",
    "logging.set_verbosity(0)\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import json\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=r\"/atidata/demo/comstar/2021-09-21-08-53-57-mini20-03-manual_comstar_mapping_run/\"\n",
    "map_dir=r\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Submap:\n",
    "    def __init__(self, pose, grid_res, grid_alpha):\n",
    "        self.pose = pose.copy()\n",
    "        self.grid_alpha = grid_alpha\n",
    "        self.grid_res = grid_res\n",
    "        self.grid = Grid2D(self.grid_alpha, self.grid_res )\n",
    "        self.num_insertions = 0\n",
    "        self.finished = False\n",
    "        self.node_ids = []\n",
    "        self.frame_ids = []\n",
    "        self.local_insertion_poses = None\n",
    "    \n",
    "    def search(self, frame, search_space, count_once = True):\n",
    "        return self.grid.search(frame, search_space, count_once=count_once)\n",
    "    \n",
    "    def insert_points(self, frame, pose, frame_id, node_id):        \n",
    "        if not self.finished:\n",
    "            self.num_insertions +=1\n",
    "            self.grid.insert_points(pose, frame)\n",
    "            self.node_ids.append(node_id)\n",
    "            self.frame_ids.append(frame_id)\n",
    "            if self.local_insertion_poses is None:\n",
    "                self.local_insertion_poses = pose.reshape(1,3)\n",
    "            else:\n",
    "                self.local_insertion_poses = np.concatenate((self.local_insertion_poses, pose.reshape(1,3)), axis = 0)\n",
    "        else:\n",
    "            print(\"Submap update is finished. Not inserting \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2D_rotation_mat(theta):\n",
    "    cth = np.cos(theta)\n",
    "    sth = np.sin(theta)\n",
    "    return np.array([[cth, -sth],\n",
    "                    [sth, cth]])\n",
    "\n",
    "def get_angle_from_2D_rotation_mat(R):\n",
    "    return np.arctan2(R[1,0], R[0,0])\n",
    "\n",
    "def get_yelli_rotation(theta):\n",
    "    th = theta - np.pi/2\n",
    "    R = get_2D_rotation_mat(th)\n",
    "    return R\n",
    "\n",
    "def get_inverse_yelli_rotation(theta):\n",
    "    return get_yelli_rotation(theta).T\n",
    "\n",
    "def get_yelli_transform(pose):\n",
    "    R = get_yelli_rotation(pose[2])\n",
    "    t = pose[:2]\n",
    "    return R,t\n",
    "\n",
    "def get_inverse_yelli_transform(pose):\n",
    "    R = get_inverse_yelli_rotation(pose[2])\n",
    "    t = -R @ pose[:2].reshape(2,1)\n",
    "    return R,t.flatten()\n",
    "\n",
    "def normalize_pose(theta):\n",
    "    theta = np.arctan2(np.sin(theta), np.cos(theta))\n",
    "    return theta\n",
    "\n",
    "def get_inverse_yelli_pose(pose):\n",
    "    #theta = -pose[2] + np.pi\n",
    "    #theta = normalize_pose(theta)\n",
    "    R,t = get_inverse_yelli_transform(pose) \n",
    "    theta = get_angle_from_2D_rotation_mat(R) + np.pi/2 \n",
    "    theta = normalize_pose(theta)\n",
    "    return np.array([t[0], t[1], theta])\n",
    "\n",
    "\n",
    "\n",
    "def combine_yelli_poses(p1, p2):\n",
    "    R1,t1 = get_yelli_transform(p1)\n",
    "    R2,t2 = get_yelli_transform(p2)\n",
    "    R = R1 @ R2\n",
    "    t = (t1.reshape(2,1) + R1 @ t2.reshape(2,1)).flatten()\n",
    "    theta = get_angle_from_2D_rotation_mat(R) + np.pi/2\n",
    "    theta = normalize_pose(theta)\n",
    "    return np.array([t[0], t[1], theta])\n",
    "    \n",
    "def imu_submap_pose_estimate(imu_tracker, time, submap_pose, pose):\n",
    "    spose = combine_yelli_poses(pose, get_inverse_yelli_pose(submap_pose))\n",
    "    dquat = imu_tracker.get_gyro_quaternion(time)\n",
    "    dtheta = qe.get_roll_pitch_yaw_from_quaternion(dquat)[-1]\n",
    "    pose_estimate = np.copy(spose)\n",
    "    pose_estimate[2] += dtheta\n",
    "    return pose_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e7efd9ea7aed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimu_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimu_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimu_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimu_ts\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "max_frames = 32000 \n",
    "data_dir = dataset\n",
    "imu_data = load_data(data_dir)\n",
    "ts = np.mean(np.diff(imu_data.time))\n",
    "dt = imu_ts[np.argmin(np.abs(imu_ts - ts))]\n",
    "#imu_tracker = ImuTracker(dt)\n",
    "imu_tracker = ImuTracker()\n",
    "imu_bias_initialized = False\n",
    "i = 0\n",
    "print(f\"\")\n",
    "while not imu_bias_initialized:\n",
    "    imu_bias_initialized = imu_tracker.get_initial_gyro_bias(imu_data.iloc[i])\n",
    "    i += 1\n",
    "best_scores, poses, frame_list = [], [], []\n",
    "submaps = []\n",
    "\n",
    "z_slices = [(zmin,zmax)]\n",
    "\n",
    "print(\"Using Z slices:\", z_slices)\n",
    "\n",
    "#pose = np.array([[0, 0, np.pi / 2 + tilt]] * len(z_slices))\n",
    "pose = np.array([0.,0., np.pi/2])\n",
    "prev_pose = pose.copy()\n",
    "\n",
    "active_submaps = []\n",
    "finished_submaps = []\n",
    "\n",
    "spose = pose\n",
    "#spose = np.array([1,2,0])\n",
    "submap = Submap(spose.copy(), grid_res, grid_alpha)\n",
    "active_submaps.append(submap)\n",
    "\n",
    "node_poses = []\n",
    "insertion_fr_ids=[]\n",
    "\n",
    "i, frame_id = 0, -1\n",
    "debug_data_dir = data_dir\n",
    "bootstrap_frames =20\n",
    "try:\n",
    "    lpb = lidar_pb.LidarSmallPb(data_dir)\n",
    "except:\n",
    "    lpb = lidar_pb.LidarPb(data_dir)\n",
    "prev_frame_time, prev_frame = lpb.get_frame(start_frame - 2)\n",
    "\n",
    "# if use_16_beams:\n",
    "#     if prev_frame.shape[0] == 32768:\n",
    "#         print(\"data has 16 beams only\")\n",
    "#         use_16_beams = False\n",
    "#     else:\n",
    "#         print(\"using 16 beams only\")\n",
    "\n",
    "num_frames = np.minimum(len(lpb.list_frames()), max_frames)\n",
    "print(f\"total frames {num_frames}\")\n",
    "filtered_pts = []\n",
    "for frame_id in range(start_frame, num_frames - 1):\n",
    "    #if frame_id % 2 != 0:\n",
    "        #continue\n",
    "    try:\n",
    "        frame_time, frame = lpb.get_frame(frame_id)\n",
    "    except:\n",
    "        print(f\"skipping {frame_id}. divide-by-zero error\")\n",
    "        continue\n",
    "\n",
    "    frame = np.copy(frame[:, :6]).astype(np.float64)\n",
    "#     if use_16_beams:\n",
    "#         ##### fix for 32 beams\n",
    "#         frame = frame.reshape(-1,2048,6)\n",
    "#         if frame.shape[0] == 32:\n",
    "#             # select any 16 beams\n",
    "#             beams = [1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31]\n",
    "#             frame = frame[beams]\n",
    "#         frame = frame.reshape(-1,6)\n",
    "#         ##### fix for 32 beams\n",
    "\n",
    "#     if correct_roll_pitch:\n",
    "#         frame, roll, pitch = lidar_utils.correct_tilt(\n",
    "#             frame, roll, pitch, lidar_ht=lidar_ht, use_cuda=use_cuda\n",
    "#         )\n",
    "#         if abs(roll) > 0.05 or abs(pitch) > 0.05:\n",
    "#             print(f\"Warning: Roll {roll:.2f}, Pitch  {pitch:0.2f}\")\n",
    "\n",
    "    frame = frame[(frame[:,4]>0) & (frame[:,4] < 60)]\n",
    "    frame = frame[(frame[:,2] > zmin) & (frame[:,2] < zmax)]\n",
    "    \n",
    "    #filtered_frame = voxel_filter(frame, voxel_size=0.05)\n",
    "    filtered_frame,_ = voxel_filter_fast(voxel_filter(frame, voxel_size=0.05), trunc=False, voxel = 0.5)\n",
    "    #filtered_frame_z = multimap.split_frame(filtered_frame)\n",
    "    \n",
    "    frame_z = voxel_filter(frame[:,:3], voxel_size=0.05)\n",
    "\n",
    "    \n",
    "    #filtered_pts.append(filtered_frame_z[0].shape[0])\n",
    "\n",
    "    if frame_id < start_frame + bootstrap_frames:\n",
    "        #multimap.insert_points(filtered_frame_z, pose[0])\n",
    "        #print(\"pose\", pose, frame_z.shape)\n",
    "        print(\"Num Bootstrap insertions\", active_submaps[0].num_insertions)\n",
    "        #ANUJ: local submap pose\n",
    "        spose = combine_yelli_poses(pose, get_inverse_yelli_pose(active_submaps[0].pose))\n",
    "        node_poses.append(pose) #ANUJ: Node is every inserted pose\n",
    "        insertion_fr_ids.append(frame_id)\n",
    "        active_submaps[0].insert_points(frame_z, spose, frame_id, node_id = len(node_poses)-1 )\n",
    "        frame_list.append(frame_id)\n",
    "        poses.append(pose)\n",
    "        prev_insert_ts = frame_time\n",
    "        prev_frame_time, prev_frame = frame_time, frame\n",
    "        last_inserted_pose = pose.copy()\n",
    "        continue\n",
    "\n",
    "    relevant_imu_data = imu_data[imu_data[\"time\"].between(prev_frame_time, frame_time)]\n",
    "    for imu_idx in range(relevant_imu_data.shape[0]):\n",
    "        imu_tracker.add_imu_data(relevant_imu_data.iloc[imu_idx])\n",
    "\n",
    "    pose_estimate = imu_pose_estimate(imu_tracker, frame_time, pose)\n",
    "    spose_estimate = combine_yelli_poses(get_inverse_yelli_pose(active_submaps[0].pose),pose_estimate)\n",
    "    #spose_estimate = imu_submap_pose_estimate(imu_tracker, frame_time, active_submaps[0].pose, pose)\n",
    "    #print(frame_id,pose_estimate)\n",
    "    search_space = utils.grid_space(center=spose_estimate, **grid_params)\n",
    "    #scores = multimap.search(filtered_frame_z, search_space)\n",
    "    #print()\n",
    "    scores = active_submaps[0].search(filtered_frame, search_space, count_once = False)\n",
    "    #print(scores)\n",
    "    best = np.argmax(scores)\n",
    "    #pose = [search_space[b] for b in best]\n",
    "    #best_scores.append([scores[i][b] for i, b in enumerate(best)])\n",
    "    best_scores.append(scores[best])\n",
    "    #pose = select_best_pose(pose, best_scores[-1])\n",
    "    \n",
    "    spose = search_space[best]\n",
    "    pose = combine_yelli_poses(active_submaps[0].pose, spose)\n",
    "    \n",
    "    \n",
    "    #print(pose)\n",
    "    #if (np.linalg.norm(pose[:2]-prev_pose[:2])> 0.1 or (prev_insert_ts - frame_time)>1) :\n",
    "    if (np.linalg.norm(pose[:2]-last_inserted_pose[:2])> 0.1 or (prev_insert_ts - frame_time)>1) :\n",
    "        #multimap.insert_points(filtered_frame_z, pose[0])\n",
    "        #multimap.insert_points(frame_z, pose[0])\n",
    "        \n",
    "        #print(\"Num insertions\", active_submaps[0].num_insertions)\n",
    "        #print(\"Fr id\", frame_id)\n",
    "        #print(\"sub pose\", active_submaps[0].pose)\n",
    "        node_poses.append(pose)\n",
    "        insertion_fr_ids.append(frame_id)\n",
    "        active_submaps[0].insert_points(frame_z, spose, frame_id, node_id=len(node_poses)-1)\n",
    "        if len(active_submaps) ==1:\n",
    "            \n",
    "            if active_submaps[0].num_insertions >= int(num_submap_range_data/2):\n",
    "                active_submaps.append(Submap(pose.copy(), grid_res, grid_alpha))\n",
    "                s2pose = combine_yelli_poses(get_inverse_yelli_pose(active_submaps[1].pose),pose)\n",
    "                active_submaps[1].insert_points(frame_z,s2pose, frame_id, node_id=len(node_poses)-1)\n",
    "                #print(f\"spose {spose}, s2pose {s2pose}\")\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            s2pose = combine_yelli_poses(get_inverse_yelli_pose(active_submaps[1].pose),pose)\n",
    "            active_submaps[1].insert_points(frame_z,s2pose, frame_id, node_id=len(node_poses)-1)\n",
    "            #print(f\"len else spose {spose}, s2pose {s2pose}\")\n",
    "            \n",
    "        if active_submaps[0].num_insertions >= num_submap_range_data - 1:\n",
    "            active_submaps[0].finished = True\n",
    "            finished_submaps.append(active_submaps.pop(0))\n",
    "            active_submaps.append(Submap(pose.copy(), grid_res, grid_alpha))\n",
    "            s2pose = combine_yelli_poses(get_inverse_yelli_pose(active_submaps[1].pose), pose)\n",
    "            active_submaps[1].insert_points(frame_z,s2pose, frame_id, node_id=len(node_poses)-1)\n",
    "        \n",
    "        #print(\"num active submaps\", len(active_submaps))\n",
    "        prev_insert_ts = frame_time\n",
    "        last_inserted_pose = pose.copy()\n",
    "    #multimap.insert_points(filtered_frame_z, pose[0])\n",
    "     \n",
    "    prev_pose = pose.copy()\n",
    "    frame_list.append(frame_id)    \n",
    "    poses.append(pose)\n",
    "    if frame_id % 250 == 0:\n",
    "        print(\n",
    "            f\"frame:{frame_id} scores:{best_scores[-1]} best pose:{pose}  \"\n",
    "        )\n",
    "    prev_frame_time, prev_frame = frame_time, frame\n",
    "\n",
    "#multimap.transform_scores()\n",
    "poses = np.array(poses)\n",
    "node_poses = np.array(node_poses)\n",
    "insertion_fr_ids = np.array(insertion_fr_ids)\n",
    "\n",
    "print(f\"final pose {poses[-1]}\")\n",
    "#print(f\"Min points in frame: {np.min(filtered_pts)}\")\n",
    "# if pruned:\n",
    "#     print(\"Pruning the map..\")\n",
    "#     grid_x_limit, grid_y_limit = get_prune_limits(multimap.maps[0], poses)\n",
    "#     multimap = prune_map(multimap, grid_x_limit, grid_y_limit)\n",
    "# if not save_as_float:\n",
    "#     multimap.maps[0].grid = (multimap.maps[0].grid * 128).astype(np.uint8)\n",
    "#     multimap.maps[0].origin.dtype = \"float\"\n",
    "# multimap.save_map(map_name)\n",
    "# np.save(f\"{map_name}/yelli_poses.npy\", poses)\n",
    "# np.save(f\"{map_name}/yelli_frames.npy\", frame_list)\n",
    "# with open(os.path.join(map_name, \"map_metadata.json\"), \"w\") as f:\n",
    "#     json.dump(generate_map_metadata(data_dir), f)\n",
    "# quality = map_quality(multimap.maps[0].grid)\n",
    "# print(f\"map quality {quality}\")\n",
    "# alpha_arr = [1.0, 0.7]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
